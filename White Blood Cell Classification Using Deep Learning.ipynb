{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Activation, Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path='./config.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Images and Creating Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(image_files_list, resize_factor=1):\n",
    "    '''\n",
    "    Load images from file paths and put together as numpy array.\n",
    "     '''\n",
    "    for i, image_file in enumerate(tqdm.tqdm(image_files_list)):\n",
    "        img = Image.open(image_file)            \n",
    "\n",
    "        if resize_factor > 1:\n",
    "            img = img.resize((int(img.width/resize_factor), int(img.height/resize_factor)))\n",
    "\n",
    "        # convert the image to numpy array and normalize pixel values\n",
    "        data = np.asarray(img, dtype=np.float32)/255 \n",
    "        \n",
    "        if i == 0:                \n",
    "            #initialize array to return\n",
    "            ret = np.empty((len(image_files_list), *data.shape), dtype=np.float32)\n",
    "\n",
    "        ret[i] = data\n",
    "    return ret\n",
    "\n",
    "def get_image_array_and_labels(path_to_types_folders, resize_factor=1):\n",
    "    \n",
    "    '''Returns array containing all images under path_to_types_folders and array containing corresponding labels'''\n",
    "    \n",
    "    #Mapping of white blood cell types to ints\n",
    "    type_to_int = {'EOSINOPHIL': 0, 'LYMPHOCYTE': 1, 'MONOCYTE': 2, 'NEUTROPHIL': 3}\n",
    "    \n",
    "    type_folders = os.listdir(path_to_types_folders)\n",
    "    image_files = []\n",
    "    image_labels = []\n",
    "    \n",
    "    #Get files and labels for images under folders for each type of white blood cell\n",
    "    for type_folder in types_folders:\n",
    "        folder_path = os.path.join(path_to_types_folders, type_folder)\n",
    "        files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.lower().endswith('.jpeg')]\n",
    "        labels = [type_to_int[type_folder]] * len(files)\n",
    "        image_files.extend(files)\n",
    "        image_labels.extend(labels)\n",
    "        \n",
    "    images_array = load_images(image_files, resize_factor)\n",
    "    image_labels = np.array(image_labels, dtype=np.uint8)\n",
    "    return images_array, image_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_image_array_and_labels(os.getenv('PATH_TO_TRAIN'))\n",
    "X_test, y_test = get_image_array_and_labels(os.getenv('PATH_TO_TEST'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert labels to one hot encoding\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b76103b96bf1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Layer 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "#Input\n",
    "x_input = Input(shape=X_test.shape[1:])\n",
    "\n",
    "# Layer 1\n",
    "x = Conv2D(filters=32, kernel_size=3, activation='relu')(x_input)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Dropout(rate=0.25)(x)\n",
    "\n",
    "# Layer 2\n",
    "x = Conv2D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Dropout(rate=0.25)(x)\n",
    "\n",
    "# Fully Connected Network layer\n",
    "x = Flatten()(x)\n",
    "x = Dense(units=128, activation='relu')(x)\n",
    "x = Dropout(rate=0.25)(x)\n",
    "\n",
    "# Output\n",
    "x = Dense(units=4, activation='softmax')(x)\n",
    "\n",
    "# Build model \n",
    "model1 = Model(inputs=x_input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and Train Model\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "history1 = model1.fit(x=X_train, y=y_train_one_hot, epochs=150, batch_size=64, validation_split=0.1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Trained Model on Test Data\n",
    "y1_predict = model1.predict(X_test).argmax(axis=1)\n",
    "model1_test_acc = (y1_predict == y_test).sum()/(y1_predict.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "x_input = Input(shape=X_test.shape[1:])\n",
    "    \n",
    "# Layer 1\n",
    "x = Conv2D(filters=32, kernel_size=3, activation='relu', padding='same')(x_input)\n",
    "x = Dropout(rate=0.25)(x)\n",
    "    \n",
    "# Layer 2\n",
    "x = Conv2D(filters=32, kernel_size=3, activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Dropout(rate=0.40)(x)\n",
    "    \n",
    "# Layer 3\n",
    "x = Conv2D(filters=64, kernel_size=3, activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Dropout(rate=0.40)(x)\n",
    "    \n",
    "# Fully Connected Network Layer\n",
    "x = Flatten()(x)      \n",
    "x = Dense(units=64, activation='relu')(x)\n",
    "x = Dropout(rate=0.40)(x)\n",
    "    \n",
    "# Output\n",
    "x = Dense(units=4, activation='softmax')(x)\n",
    "\n",
    "# Build Model\n",
    "model2 = Model(inputs=x_input, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and Train Model\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "history2 = model2.fit(x=X_train, y=y_train_one_hot, epochs=150, batch_size=64, validation_split=0.1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Trained Model on Test Data\n",
    "y2_predict = model1.predict(X_test).argmax(axis=1)\n",
    "model2_test_acc = (y2_predict == y_test).sum()/(y2_predict.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input\n",
    "x_input = Input(shape=X_test.shape[1:])\n",
    "    \n",
    "# Layer 1\n",
    "x = Conv2D(filters=64, kernel_size=3, activation='relu', padding='same')(x_input)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Dropout(rate=0.25)(x)\n",
    "    \n",
    "# Layer 2\n",
    "x = Conv2D(filters=32, kernel_size=3, activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Dropout(rate=0.25)(x)\n",
    "    \n",
    "# Layer 3\n",
    "x = Conv2D(filters=32, kernel_size=3, activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Dropout(rate=0.4)(x)\n",
    "    \n",
    "# Layer 4\n",
    "x = Conv2D(filters=32, kernel_size=3, activation='relu')(x)\n",
    "x = Dropout(rate=0.4)(x)\n",
    "\n",
    "# Fully Connected Network Layer\n",
    "x = Flatten()(x)      \n",
    "x = Dense(units=128, activation='relu')(x)\n",
    "x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "# Output\n",
    "x = Dense(units=4, activation='softmax')(x)\n",
    "\n",
    "# Build Model\n",
    "model3 = Model(inputs=x_input, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and Train Model\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "history3 = model3.fit(x=X_train, y=y_train_one_hot, epochs=150, batch_size=64, validation_split=0.1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Trained Model on Test Data\n",
    "y3_predict = model3.predict(X_test).argmax(axis=1)\n",
    "model2_test_acc = (y3_predict == y_test).sum()/(y3_predict.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(title, class_labels, cm, ax=None):\n",
    "    '''\n",
    "    From https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html    \n",
    "    '''    \n",
    "    \n",
    "    if isinstance(class_labels, dict):\n",
    "        class_labels = [class_labels[k] for k in sorted(class_labels.keys())]\n",
    "    if isinstance(cm, list):\n",
    "        cm = np.asarray(cm)\n",
    "    \n",
    "    assert cm.shape == (len(class_labels), len(class_labels))\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    # each row corresponds to total true labels for the class\n",
    "    class_totals = cm.sum(axis=1, keepdims=True)\n",
    "    cm_pct  = 100*cm/class_totals\n",
    "    im = ax.imshow(cm_pct, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.get_figure().colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]))\n",
    "    \n",
    "    ax.set_title(title + ' Confusion Matrix', fontsize=14)    \n",
    "    ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "    ax.set_ylabel('True Label', fontsize=12)\n",
    "\n",
    "    ax.set_xticklabels(class_labels, fontsize=8, rotation=45)\n",
    "    ax.set_yticklabels(class_labels, fontsize=8)\n",
    "\n",
    "    \n",
    "    # show text annotations\n",
    "    thresh = cm_pct.max()/2\n",
    "    for i in range(cm_pct.shape[0]):\n",
    "        for j in range(cm_pct.shape[1]):\n",
    "            c = 'white' if cm_pct[i, j] > thresh else 'black'\n",
    "            ax.text(j, i, f\"{cm_pct[i, j]:.1f}%\", ha='center', va='center', color=c)\n",
    "    if ax is None:\n",
    "        fig.tight_layout() \n",
    "\n",
    "\n",
    "def plot_results(model_name, history, y_test, y_predict):\n",
    "    '''\n",
    "    Creates and saves two plots:\n",
    "       1. Training and validation accuracy graph\n",
    "       2. Confusion matrix\n",
    "    '''\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14,5))\n",
    "    \n",
    "    # Plot training and validation accuracy \n",
    "    train_acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    axs[0].plot(range(1, 1+len(train_acc)), train_acc, label='train_acc')\n",
    "    axs[0].plot(range(1, 1+len(val_acc)), val_acc, label='val_acc')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xticks(range(1, 1+len(val_acc)))\n",
    "    axs[0].legend()\n",
    "    axs[0].set_title(model_name + ' Accuracy History')\n",
    "\n",
    "    # Plot Confusion Matrix \n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    class_labels = ['EOSINOPHIL', 'LYMPHOCYTE', 'MONOCYTE', 'NEUTROPHIL']\n",
    "    plot_confusion_matrix(model_name, class_labels, cm, ax=axs[1])\n",
    "    png_file = model_name + '_results.png'\n",
    "    plt.savefig(png_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting results for all models\n",
    "plot_results('Model 1', history1, y_test, y1_predict)\n",
    "plot_results('Model 2', history2, y_test, y2_predict)\n",
    "plot_results('Model 3', history3, y_test, y3_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
